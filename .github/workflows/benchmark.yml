name: Benchmark

on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write

jobs:
  benchmark:
    name: benchmark
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y clang llvm libbpf-dev libsystemd-dev pkg-config cmake ninja-build libgtest-dev libbenchmark-dev

      - name: Configure
        run: cmake -S . -B build-bench -G Ninja -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTING=ON -DSKIP_BPF_BUILD=ON

      - name: Build benchmarks
        run: cmake --build build-bench --target aegisbpf_bench --target aegisbpf_bench_syscall

      - name: Run benchmarks
        run: |
          RUNNER="./build-bench/aegisbpf_bench"
          if command -v taskset >/dev/null 2>&1; then
            RUNNER="taskset -c 0 ${RUNNER}"
          fi
          ${RUNNER} \
            --benchmark_min_time=1s \
            --benchmark_repetitions=12 \
            --benchmark_report_aggregates_only=true \
            --benchmark_format=json \
            --benchmark_out=benchmark.raw.json \
            --benchmark_out_format=json

      - name: Filter unstable benchmark rows
        run: |
          python3 scripts/filter_benchmark_results.py \
            --input benchmark.raw.json \
            --output benchmark.json \
            --min-mean-time-ns 50

      - name: Check benchmark history branch
        id: benchmark-history
        run: |
          if git ls-remote --exit-code --heads origin gh-pages >/dev/null 2>&1; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Store benchmark result (PR advisory)
        if: steps.benchmark-history.outputs.exists == 'true' && github.event_name == 'pull_request'
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: googlecpp
          output-file-path: benchmark.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: false
          alert-threshold: '120%'
          fail-on-alert: false
          comment-on-alert: false
          summary-always: true

      - name: Store benchmark result (main advisory)
        if: steps.benchmark-history.outputs.exists == 'true' && github.event_name != 'pull_request'
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: googlecpp
          output-file-path: benchmark.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: ${{ github.ref == 'refs/heads/main' }}
          alert-threshold: '115%'
          fail-on-alert: false
          comment-on-alert: true
          summary-always: true

      - name: Perf gate policy note
        if: github.event_name != 'pull_request'
        run: |
          echo "Hosted benchmark-action results are advisory."
          echo "Strict regression gating is enforced in .github/workflows/perf.yml on self-hosted perf runners."

      - name: Upload benchmark artifact (bootstrap)
        if: steps.benchmark-history.outputs.exists != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-result
          path: |
            benchmark.raw.json
            benchmark.json

      - name: Warn about missing benchmark history branch
        if: steps.benchmark-history.outputs.exists != 'true'
        run: |
          echo "::warning::gh-pages branch is missing. Benchmark history comparison is skipped until gh-pages is created."
